## 1. Tá»•ng Quan (Overview)

TÃ i liá»‡u nÃ y mÃ´ táº£ kiáº¿n trÃºc ká»¹ thuáº­t cho phÃ¢n há»‡ AI (AI Module) cá»§a dá»± Ã¡n **HanoiGo**. Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ theo mÃ´ hÃ¬nh **RAG (Retrieval-Augmented Generation) Enterprise-grade**, tÃ­ch há»£p cÃ¡c ká»¹ thuáº­t tÃ¬m kiáº¿m lai (Hybrid Search) vÃ  tá»‘i Æ°u hÃ³a thá»© háº¡ng (Re-ranking) Ä‘á»ƒ xá»­ lÃ½ chÃ­nh xÃ¡c cÃ¡c truy váº¥n Ä‘á»‹a Ä‘iá»ƒm phá»©c táº¡p (vÃ­ dá»¥: tÃ¬m theo ngÃµ, ngÃ¡ch).

Má»¥c tiÃªu chÃ­nh:
*   **Accuracy:** Æ¯u tiÃªn Ä‘á»™ chÃ­nh xÃ¡c tuyá»‡t Ä‘á»‘i cho cÃ¡c truy váº¥n Ä‘á»‹a chá»‰ cá»¥ thá»ƒ (Address-Aware).
*   **Cost Optimization:** Tá»‘i Æ°u chi phÃ­ Token thÃ´ng qua Caching vÃ  chiáº¿n lÆ°á»£c Context Window hiá»‡u quáº£.
*   **Modular:** Dá»… dÃ ng thay tháº¿ Model (LLM), Vector DB hoáº·c chiáº¿n lÆ°á»£c truy xuáº¥t.

***

## 2. Technology Stack (CÃ´ng Nghá»‡ Sá»­ Dá»¥ng)

### Core AI Engine
*   **Orchestration Framework:** [LangChain.js](https://js.langchain.com/) (v0.2+) - Quáº£n lÃ½ luá»“ng xá»­ lÃ½ (Chain/LCEL).
*   **LLM Provider:** OpenAI API (`gpt-4o-mini`) - Model cÃ¢n báº±ng tá»‘t nháº¥t giá»¯a hiá»‡u nÄƒng vÃ  chi phÃ­.
*   **Vector Database:** [Pinecone](https://www.pinecone.io/) (Serverless mode) - LÆ°u trá»¯ Embeddings.
*   **Embedding Model:** `text-embedding-3-large` (OpenAI).

### Performance & Quality
*   **Retrieval Strategy:** **Hybrid Search**
    *   Vector Search (Semantic): TÃ¬m kiáº¿m theo ngá»¯ nghÄ©a.
    *   Keyword Search (MongoDB): TÃ¬m kiáº¿m Text & Regex (há»— trá»£ "ngÃµ", "ngÃ¡ch", "phá»‘" smart matching).
*   **Reranking:** [Cohere Rerank](https://cohere.com/rerank) (`rerank-multilingual-v3.0`) - Sáº¯p xáº¿p láº¡i danh sÃ¡ch káº¿t quáº£ dá»±a trÃªn Ä‘á»™ liÃªn quan ngá»¯ nghÄ©a sÃ¢u.
*   **Local Reordering:** Thuáº­t toÃ¡n tÃ¹y chá»‰nh Ä‘á»ƒ boost Ä‘iá»ƒm cho cÃ¡c Ä‘á»‹a Ä‘iá»ƒm khá»›p chÃ­nh xÃ¡c tÃªn hoáº·c Ä‘á»‹a chá»‰ (Address Boosting).
*   **Semantic Caching:** Redis (In-Memory) - Cache toÃ n bá»™ **Payload** (CÃ¢u tráº£ lá»i + Danh sÃ¡ch Ä‘á»‹a Ä‘iá»ƒm + Context) Ä‘á»ƒ Ä‘áº£m báº£o Ä‘á»“ng nháº¥t UI khi cache hit.

### Infrastructure
*   **Runtime:** Node.js (v20+ LTS).
*   **Language:** JavaScript (ES Modules).

***

## 3. Cáº¥u TrÃºc Dá»± Ãn (Enterprise Folder Structure)

```plaintext
server/services/ai/
â”œâ”€â”€ config/                     # Cáº¥u hÃ¬nh táº­p trung
â”œâ”€â”€ core/                       # LLM & DB Connection
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â”œâ”€â”€ system.v1.txt       # Persona (Fong)
â”‚   â”‚   â”œâ”€â”€ rag_query.v1.txt    # Standard RAG Prompt
â”‚   â”‚   â”œâ”€â”€ itinerary_gen.v1.txt # JSON Prompt cho lá»‹ch trÃ¬nh
â”‚   â”‚   â”œâ”€â”€ intent_classify.v1.txt # Prompt phÃ¢n loáº¡i Ã½ Ä‘á»‹nh
â”‚   â””â”€â”€ promptLoader.js         
â”œâ”€â”€ retrieval/                  # Search strategies & Reranker
â”œâ”€â”€ pipelines/
â”‚   â””â”€â”€ mainChatPipeline.js     # Router Pattern Orchestrator:
â”‚                               # 1. Input Guard
â”‚                               # 2. Intent Classify (Itinerary vs Chat)
â”‚                               # 3. Weather/Time Context Injection
â”‚                               # 4. Branch Execution
â”‚                               # 5. Output Format
â”œâ”€â”€ guardrails/
â””â”€â”€ index.js                    
```

### External Services
*   **Weather Provider:** [Open-Meteo](https://open-meteo.com/) - Dá»¯ liá»‡u thá»i tiáº¿t Real-time & Forecast.
*   **LLM Provider:** OpenAI API (`gpt-4o-mini`).
*   **Vector DB:** Pinecone (Serverless).
*   **Reranker:** Cohere Rerank.

***

### 4. Luá»“ng Dá»¯ Liá»‡u Chi Tiáº¿t (Data Flow)

Biá»ƒu Ä‘á»“ luá»“ng xá»­ lÃ½ request chuáº©n cho `mainChatPipeline.js`:

```mermaid
graph TD
    A[Request + Context (Weather)] --> B{Input Guard}
    B -- Safe --> C[Intent Classifier]
    
    C -- "ITINERARY" --> D1[Itinerary Pipeline]
    C -- "CHAT" --> D2[General Pipeline]

    subgraph "D2: General Pipeline"
        D2 --> E1[Inject Weather Context]
        E1 --> E2[Hybrid Retrieval (Vector + Keyword)]
        E2 --> E3[Semantic Rerank]
        E3 --> E4[LLM Generation (Answer + Place IDs)]
    end

    subgraph "D1: Itinerary Pipeline"
        D1 --> F1[Broad Retrieval]
        F1 --> F2[Structured Planner LLM]
        F2 --> F3[JSON-Based Plan Generation]
    end
    
    E4 & F3 --> G{Response Formatter}
    G --> H[Final Client Response]
```
    
    F --> G[Hybrid Retrieval Operations]
    
    subgraph "Stage 3.5: Hybrid Retrieval"
        G --> H1[Pinecone Vector Search]
        G --> H2[Mongo Text/Regex Search]
        H2 -- Address Detection --> H3[Smart Address Regex]
    end
    
    H1 & H2 & H3 --> I[Raw Candidate List (Top 20)]
    
    I --> J[Cohere Reranker (Top 10)]
    J -- Semantic Filter --> K[Local Reorder]
    
    K -- Name/Address Boost --> L[Optimized Context]
    
    L --> M[LLM Generation (GPT-4o-mini)]
    M --> N[Generated Answer]
    
    subgraph "Post-Processing (Route Layer)"
        N --> O[Extract Place IDs]
        O --> P[Fetch Full Data (MongoDB)]
        P --> Q[**Answer-Aware Reordering**]
        Q -- Sync UI with Text --> R[Final JSON Response]
    end
```

***

## 5. Tá»‘i Æ¯u HÃ³a Hiá»‡u NÄƒng & Cháº¥t LÆ°á»£ng (Optimization Config)

Há»‡ thá»‘ng Ä‘Æ°á»£c tinh chá»‰nh vá»›i cÃ¡c tham sá»‘ "VÃ ng" Ä‘á»ƒ cÃ¢n báº±ng giá»¯a tá»‘c Ä‘á»™ vÃ  Ä‘á»™ chÃ­nh xÃ¡c:

### ğŸš€ Performance (Hiá»‡u Suáº¥t)
*   **Model**: `gpt-4o-mini` (latency < 4s, cost ~1/30 GPT-4).
*   **Vector Search**: `TOP_K = 20`. Láº¥y rá»™ng Ä‘á»ƒ trÃ¡nh bá» sÃ³t (High Recall).
*   **Caching**: Redis Semantic Cache (TTL 1h) giÃºp giáº£m 30-50% request láº·p láº¡i.

### â­ Quality (Cháº¥t LÆ°á»£ng)
*   **Reranking**: `Cohere v3` (`TOP_K = 10`). Lá»c ká»¹ láº¡i 20 káº¿t quáº£ thÃ´ Ä‘á»ƒ chá»n ra 10 káº¿t quáº£ tinh tÃºy nháº¥t cho LLM.
*   **Strict Location**: Prompt Ä‘Æ°á»£c cáº¥u hÃ¬nh Ä‘á»ƒ "Cáº£nh bÃ¡o" náº¿u khÃ´ng tÃ¬m tháº¥y quÃ¡n Ä‘Ãºng khu vá»±c (trÃ¡nh Hallucination).
*   **UI Synchronization**: Thuáº­t toÃ¡n "Answer-Aware Reordering" sáº¯p xáº¿p láº¡i danh sÃ¡ch hiá»ƒn thá»‹ khá»›p 100% vá»›i thá»© tá»± xuáº¥t hiá»‡n trong cÃ¢u tráº£ lá»i (xá»­ lÃ½ cáº£ viáº¿t táº¯t, tÃªn phá»¥).

### ğŸ§© Review & Multilingual Strategy (Chiáº¿n lÆ°á»£c ÄÃ¡nh giÃ¡ & Äa ngÃ´n ngá»¯)
*   **Táº¡i sao lÆ°u Review vÃ o Pinecone?**
    *   Review chá»©a cÃ¡c "tá»« khÃ³a cáº£m xÃºc" (clean, cozy, noisy, friendly) mÃ  dá»¯ liá»‡u tÄ©nh khÃ´ng cÃ³.
    *   VÃ­ dá»¥: User tÃ¬m *"quÃ¡n toilet sáº¡ch"*, chá»‰ cÃ³ trong review má»›i nháº¯c Ä‘áº¿n.
*   **CÃ¡ch thá»©c (Aggregation)**:
    *   Thay vÃ¬ lÆ°u má»—i review lÃ  1 vector (gÃ¢y loÃ£ng káº¿t quáº£), ta **gá»™p Top 3 review cháº¥t lÆ°á»£ng nháº¥t** ( > 4 sao, dÃ i > 10 kÃ½ tá»±) vÃ o tháº³ng vÄƒn báº£n mÃ´ táº£ cá»§a Ä‘á»‹a Ä‘iá»ƒm (`PageContent`).
    *   Khi tÃ¬m kiáº¿m, náº¿u vector khá»›p vá»›i ná»™i dung review, há»‡ thá»‘ng sáº½ tráº£ vá» **Äá»‹a Ä‘iá»ƒm** Ä‘Ã³.
*   **Äa ngÃ´n ngá»¯ (Multilingual)**:
    *   Model `text-embedding-3-small` há»— trá»£ tá»‘t viá»‡c mapping Ã½ nghÄ©a xuyÃªn ngÃ´n ngá»¯.
    *   Review tiáº¿ng HÃ n ("matjib" - ngon) váº«n sáº½ khá»›p vá»›i query tiáº¿ng Viá»‡t ("quÃ¡n ngon") hoáº·c tiáº¿ng Anh ("tasty").

***
*TÃ i liá»‡u nÃ y Ä‘Æ°á»£c cáº­p nháº­t láº§n cuá»‘i vÃ o: 12/01/2026 bá»Ÿi HanoiGo Team.*